{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################ import libraries ############################################\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from resampling_data import DataProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                TIMESTAMP     open     high      low    close\n",
      "0     2018-10-10 09:15:00   136.50   137.35   135.00   136.40\n",
      "1     2018-10-10 09:30:00   136.35   136.70   135.25   135.95\n",
      "2     2018-10-10 09:45:00   136.00   136.30   135.70   135.70\n",
      "3     2018-10-10 10:00:00   135.80   137.95   135.80   137.50\n",
      "4     2018-10-10 10:15:00   137.35   138.50   137.10   138.00\n",
      "...                   ...      ...      ...      ...      ...\n",
      "34726 2024-02-29 14:30:00  3255.05  3264.55  3247.25  3262.80\n",
      "34727 2024-02-29 14:45:00  3262.90  3268.05  3256.00  3261.55\n",
      "34728 2024-02-29 15:00:00  3262.45  3288.00  3260.25  3286.15\n",
      "34729 2024-02-29 15:15:00  3286.20  3304.75  3285.65  3299.90\n",
      "34730 2024-02-29 15:30:00  3285.40  3285.40  3285.40  3285.40\n",
      "\n",
      "[34731 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#################################################### resampling equity data ####################################################\n",
    "base_directory = r'C:\\Users\\user\\Desktop\\futuredata\\spot_data'\n",
    "\n",
    "# Read the CSV file into a DataFrame without header and set column names\n",
    "directory1 = os.path.join(base_directory, 'ADANIENT.csv')\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "input_data = pd.read_csv(directory1, header=None, names=['DATE', 'TIME', 'TICK_PRICE', 'VOLUME', 'OPEN_INTEREST'])\n",
    "\n",
    "# Create an instance of the DataProcessor class\n",
    "processor = DataProcessor(input_data)\n",
    "\n",
    "# Read CSV data with header\n",
    "df_with_header = processor.read_csv_with_header()\n",
    "\n",
    "# Preprocess the data\n",
    "processor.preprocess_data()\n",
    "\n",
    "# Resample the data to 5-second intervals(By default the interval is 5 seconds)\n",
    "# If you want to change the interval you can pass the interval as a parameter to the resample_data method like 1T for 1 minute AND 1H for 1 hour\n",
    "ohlc_data = processor.resample_data(interval='15T')\n",
    "\n",
    "# Print the resulting OHLC data\n",
    "print(ohlc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Convert \\'TIMESTAMP\\' column to datetime if it\\'s not already\\nohlc_data[\\'TIMESTAMP\\'] = pd.to_datetime(ohlc_data[\\'TIMESTAMP\\'])\\n\\n# Define the stock split dates\\nfirst_split_date = pd.Timestamp(\\'2019-09-27\\')\\nsecond_split_date = pd.Timestamp(\\'2021-06-22\\')\\n\\n# Adjust prices before the first split date (divide by 4)\\nohlc_data.loc[ohlc_data[\\'TIMESTAMP\\'] < first_split_date, [\\'open\\', \\'high\\', \\'low\\', \\'close\\']] /= 4\\n\\n# Adjust prices between the first and second split date (divide by 2)\\nohlc_data.loc[(ohlc_data[\\'TIMESTAMP\\'] >= first_split_date) & (ohlc_data[\\'TIMESTAMP\\'] < second_split_date), [\\'open\\', \\'high\\', \\'low\\', \\'close\\']] /= 2\\n\\n# Create the final DataFrame `df` with adjusted prices\\ndf = pd.concat([\\n    ohlc_data[ohlc_data[\\'TIMESTAMP\\'] < second_split_date][[\\'TIMESTAMP\\', \\'open\\', \\'high\\', \\'low\\', \\'close\\']],\\n    ohlc_data[ohlc_data[\\'TIMESTAMP\\'] >= second_split_date][[\\'TIMESTAMP\\', \\'open\\', \\'high\\', \\'low\\', \\'close\\']]\\n])\\n\\n# Reset index for `df` if needed\\ndf.reset_index(drop=True, inplace=True)\\n\\n# Print the results if desired\\nprint(\"Final DataFrame `df` after adjustments:\")\\nprint(df)\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################################# stock split ########################################################\n",
    "\"\"\"\n",
    "# Convert 'TIMESTAMP' column to datetime if it's not already\n",
    "ohlc_data['TIMESTAMP'] = pd.to_datetime(ohlc_data['TIMESTAMP'])\n",
    "\n",
    "# Define the stock split dates\n",
    "first_split_date = pd.Timestamp('2019-09-27')\n",
    "second_split_date = pd.Timestamp('2021-06-22')\n",
    "\n",
    "# Adjust prices before the first split date (divide by 4)\n",
    "ohlc_data.loc[ohlc_data['TIMESTAMP'] < first_split_date, ['open', 'high', 'low', 'close']] /= 4\n",
    "\n",
    "# Adjust prices between the first and second split date (divide by 2)\n",
    "ohlc_data.loc[(ohlc_data['TIMESTAMP'] >= first_split_date) & (ohlc_data['TIMESTAMP'] < second_split_date), ['open', 'high', 'low', 'close']] /= 2\n",
    "\n",
    "# Create the final DataFrame `df` with adjusted prices\n",
    "df = pd.concat([\n",
    "    ohlc_data[ohlc_data['TIMESTAMP'] < second_split_date][['TIMESTAMP', 'open', 'high', 'low', 'close']],\n",
    "    ohlc_data[ohlc_data['TIMESTAMP'] >= second_split_date][['TIMESTAMP', 'open', 'high', 'low', 'close']]\n",
    "])\n",
    "\n",
    "# Reset index for `df` if needed\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Print the results if desired\n",
    "print(\"Final DataFrame `df` after adjustments:\")\n",
    "print(df)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################### calculate EMA ####################################################\n",
    "df = ohlc_data.copy()\n",
    "i = 14\n",
    "# Calculate EMA for high and low\n",
    "df['ema_high'] = df['high'].ewm(span=i, adjust=False).mean()\n",
    "df['ema_low'] = df['low'].ewm(span=i, adjust=False).mean()\n",
    "# Initialize 'signal' column with 0\n",
    "df['signal'] = 0\n",
    "\n",
    "# Iterate through the DataFrame\n",
    "for i in range(len(df)):\n",
    "    if df['close'].iloc[i] > df['ema_high'].iloc[i]:\n",
    "        df.at[i, 'signal'] = 1\n",
    "    elif df['close'].iloc[i] < df['ema_low'].iloc[i]:\n",
    "        df.at[i, 'signal'] = -1\n",
    "\n",
    "# Apply forward fill to propagate the last valid observation forward\n",
    "df['signal'] = df['signal'].replace(0, method='ffill')\n",
    "\n",
    "# Shift the 'signal' column by 1 to move the signals to the next day\n",
    "df['signal'] = df['signal'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################### calculate expiry date and position ###########################################\n",
    "# Convert 'TIMESTAMP' to datetime\n",
    "df['TIMESTAMP'] = pd.to_datetime(df['TIMESTAMP'])\n",
    "\n",
    "# Initialize 'Expiry_Date' with None\n",
    "df['Expiry_Date'] = None\n",
    "\n",
    "# Iterate through the DataFrame\n",
    "for i in range(len(df)):\n",
    "    date = df['TIMESTAMP'].iloc[i].date()\n",
    "    day = date.day\n",
    "    month = date.month\n",
    "    year = date.year\n",
    "    if month == 12:\n",
    "        if day < 20:\n",
    "            df.at[i, 'Expiry_Date'] = f'{str(year)[2:4]}DECFUT'\n",
    "        else:\n",
    "            year += 1\n",
    "            df.at[i, 'Expiry_Date'] = f'{str(year)[2:4]}JANFUT'\n",
    "    else:\n",
    "        if day < 20:\n",
    "            df.at[i, 'Expiry_Date'] = f'{str(year)[2:4]}{date.strftime(\"%b\").upper()}FUT'\n",
    "        else:\n",
    "            next_month_date = date + pd.DateOffset(months=1)\n",
    "            df.at[i, 'Expiry_Date'] = f'{str(next_month_date.year)[2:4]}{next_month_date.strftime(\"%b\").upper()}FUT'\n",
    "\n",
    "# Initialize 'position' column with 0\n",
    "df['position'] = 0\n",
    "\n",
    "# Iterate through the DataFrame\n",
    "for i in range(1, len(df)):\n",
    "    if df['signal'].iloc[i] == 1 and df['signal'].iloc[i-1] == 0:\n",
    "        df.at[i, 'position'] = 1\n",
    "    elif df['signal'].iloc[i] == -1 and df['signal'].iloc[i-1] == 0:\n",
    "        df.at[i, 'position'] = -1\n",
    "    elif df['signal'].iloc[i] == -1 and df['signal'].iloc[i-1] == 1:\n",
    "        df.at[i, 'position'] = -1\n",
    "    elif df['signal'].iloc[i] == 1 and df['signal'].iloc[i-1] == -1:\n",
    "        df.at[i, 'position'] = 1\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed processing.\n"
     ]
    }
   ],
   "source": [
    "###################################################################### logic to get future data ########################################################\n",
    "directory = r'C:\\Users\\user\\Desktop\\futuredata'\n",
    "df['price'] = None\n",
    "\n",
    "for i in range(len(df)):\n",
    "    # Ticker symbol\n",
    "    ticker = 'ADANIENT'\n",
    "    df.at[i, 'contract_name'] = ticker + df.at[i, 'Expiry_Date']\n",
    "    df.at[i, 'date'] = df.at[i, 'TIMESTAMP'].date()\n",
    "    df.at[i, 'time'] = df.at[i, 'TIMESTAMP'].time()\n",
    "    \n",
    "    if df.at[i, 'position'] == 1 or df.at[i, 'position'] == -1:\n",
    "        base_directory = os.path.join(directory, df.at[i, 'contract_name'] + '.csv')\n",
    "        #print(f\"Processing file: {base_directory}\")\n",
    "        \n",
    "        if os.path.exists(base_directory):\n",
    "            data = pd.read_csv(base_directory)\n",
    "            #print(f\"File {base_directory} loaded successfully.\")\n",
    "            \n",
    "            # Add the header to the future contract data\n",
    "            data.columns = ['DATE', 'TIME', 'TICK_PRICE', 'VOLUME', 'OPEN_INTEREST']\n",
    "            \n",
    "            # Correctly parse the DATE column\n",
    "            data['DATE'] = pd.to_datetime(data['DATE'], format='%Y%m%d').dt.date\n",
    "            data['TIME'] = pd.to_datetime(data['TIME'], format='%H:%M:%S').dt.time\n",
    "            \n",
    "            # Debug: Print the first few rows of the data file\n",
    "            #print(\"Data file preview:\")\n",
    "            #print(data.head())\n",
    "\n",
    "            target_datetime = pd.to_datetime(df.at[i, 'date'].strftime('%Y-%m-%d') + ' ' + df.at[i, 'time'].strftime('%H:%M:%S'))\n",
    "            \n",
    "            # Combine 'DATE' and 'TIME' into a single 'DATETIME' column in data\n",
    "            data['DATETIME'] = pd.to_datetime(data['DATE'].astype(str) + ' ' + data['TIME'].astype(str))\n",
    "            \n",
    "            # Find the row with the nearest time\n",
    "            nearest_idx = (data['DATETIME'] - target_datetime).abs().argsort().iloc[0]\n",
    "            nearest_row = data.iloc[nearest_idx]\n",
    "            \n",
    "            # Check if the nearest row date matches the target date\n",
    "            if nearest_row['DATETIME'].date() == target_datetime.date():\n",
    "                df.at[i, 'price'] = nearest_row['TICK_PRICE']\n",
    "                #print(f\"Price found: {df.at[i, 'price']}\")\n",
    "                #break  # Break the loop after finding the first price\n",
    "print(\"Completed processing.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      position        date      time     contract_name   price  lot_size\n",
      "0            1  2018-10-10  10:15:00  ADANIENT18OCTFUT  137.55       300\n",
      "1           -1  2018-10-11  10:00:00  ADANIENT18OCTFUT   138.3       300\n",
      "2            1  2018-10-11  11:45:00  ADANIENT18OCTFUT  142.75       300\n",
      "3           -1  2018-10-11  14:00:00  ADANIENT18OCTFUT   140.6       300\n",
      "4            1  2018-10-12  09:30:00  ADANIENT18OCTFUT  143.15       300\n",
      "...        ...         ...       ...               ...     ...       ...\n",
      "1825         1  2024-02-23  12:30:00  ADANIENT24MARFUT  3312.8       300\n",
      "1826        -1  2024-02-27  11:00:00  ADANIENT24MARFUT  3330.6       300\n",
      "1827         1  2024-02-29  10:00:00  ADANIENT24MARFUT  3269.0       300\n",
      "1828        -1  2024-02-29  10:15:00  ADANIENT24MARFUT  3250.0       300\n",
      "1829         1  2024-02-29  11:15:00  ADANIENT24MARFUT  3278.2       300\n",
      "\n",
      "[1830 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "############################################# filterig data ########################################################\n",
    "# Filter the DataFrame where 'price' is not None\n",
    "filtered_df = df[df['price'].notna()][['position', 'date', 'time', 'contract_name', 'price']]\n",
    "\n",
    "filtered_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Assigning the Lot Size\n",
    "filtered_df['lot_size'] = 300\n",
    "\n",
    "# Display the new DataFrame\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize columns\n",
    "filtered_df['entry_price'] = None\n",
    "filtered_df['exit_price'] = None\n",
    "filtered_df['pnl'] = None\n",
    "\n",
    "# Calculate entry_price, exit_price, and pnl\n",
    "for i in range(len(filtered_df) - 1):  # Loop until second last index\n",
    "    if filtered_df.at[i, 'position'] == 1:\n",
    "        filtered_df.at[i, 'entry_price'] = filtered_df.at[i, 'price']\n",
    "        filtered_df.at[i, 'exit_price'] = filtered_df.at[i + 1, 'price']\n",
    "        filtered_df.at[i, 'pnl'] = (filtered_df.at[i + 1, 'price'] - filtered_df.at[i, 'price']) * filtered_df.at[i, 'lot_size']\n",
    "        \n",
    "    elif filtered_df.at[i, 'position'] == -1:\n",
    "        filtered_df.at[i, 'entry_price'] = filtered_df.at[i, 'price']\n",
    "        filtered_df.at[i, 'exit_price'] = filtered_df.at[i + 1, 'price']\n",
    "        filtered_df.at[i, 'pnl'] = (filtered_df.at[i, 'price'] - filtered_df.at[i + 1, 'price']) * filtered_df.at[i, 'lot_size']\n",
    "\n",
    "# Drop the last row as it won't have an exit_price\n",
    "filtered_df = filtered_df.drop(filtered_df.index[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>position</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>contract_name</th>\n",
       "      <th>price</th>\n",
       "      <th>lot_size</th>\n",
       "      <th>entry_price</th>\n",
       "      <th>exit_price</th>\n",
       "      <th>pnl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-10-10</td>\n",
       "      <td>10:15:00</td>\n",
       "      <td>ADANIENT18OCTFUT</td>\n",
       "      <td>137.55</td>\n",
       "      <td>300</td>\n",
       "      <td>137.55</td>\n",
       "      <td>138.3</td>\n",
       "      <td>225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>2018-10-11</td>\n",
       "      <td>10:00:00</td>\n",
       "      <td>ADANIENT18OCTFUT</td>\n",
       "      <td>138.3</td>\n",
       "      <td>300</td>\n",
       "      <td>138.3</td>\n",
       "      <td>142.75</td>\n",
       "      <td>-1335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-10-11</td>\n",
       "      <td>11:45:00</td>\n",
       "      <td>ADANIENT18OCTFUT</td>\n",
       "      <td>142.75</td>\n",
       "      <td>300</td>\n",
       "      <td>142.75</td>\n",
       "      <td>140.6</td>\n",
       "      <td>-645.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>2018-10-11</td>\n",
       "      <td>14:00:00</td>\n",
       "      <td>ADANIENT18OCTFUT</td>\n",
       "      <td>140.6</td>\n",
       "      <td>300</td>\n",
       "      <td>140.6</td>\n",
       "      <td>143.15</td>\n",
       "      <td>-765.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-10-12</td>\n",
       "      <td>09:30:00</td>\n",
       "      <td>ADANIENT18OCTFUT</td>\n",
       "      <td>143.15</td>\n",
       "      <td>300</td>\n",
       "      <td>143.15</td>\n",
       "      <td>173.0</td>\n",
       "      <td>8955.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>-1</td>\n",
       "      <td>2024-02-23</td>\n",
       "      <td>10:30:00</td>\n",
       "      <td>ADANIENT24MARFUT</td>\n",
       "      <td>3264.1</td>\n",
       "      <td>300</td>\n",
       "      <td>3264.1</td>\n",
       "      <td>3312.8</td>\n",
       "      <td>-14610.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-02-23</td>\n",
       "      <td>12:30:00</td>\n",
       "      <td>ADANIENT24MARFUT</td>\n",
       "      <td>3312.8</td>\n",
       "      <td>300</td>\n",
       "      <td>3312.8</td>\n",
       "      <td>3330.6</td>\n",
       "      <td>5340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1826</th>\n",
       "      <td>-1</td>\n",
       "      <td>2024-02-27</td>\n",
       "      <td>11:00:00</td>\n",
       "      <td>ADANIENT24MARFUT</td>\n",
       "      <td>3330.6</td>\n",
       "      <td>300</td>\n",
       "      <td>3330.6</td>\n",
       "      <td>3269.0</td>\n",
       "      <td>18480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1827</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-02-29</td>\n",
       "      <td>10:00:00</td>\n",
       "      <td>ADANIENT24MARFUT</td>\n",
       "      <td>3269.0</td>\n",
       "      <td>300</td>\n",
       "      <td>3269.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>-5700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1828</th>\n",
       "      <td>-1</td>\n",
       "      <td>2024-02-29</td>\n",
       "      <td>10:15:00</td>\n",
       "      <td>ADANIENT24MARFUT</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>300</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>3278.2</td>\n",
       "      <td>-8460.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1829 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      position        date      time     contract_name   price  lot_size  \\\n",
       "0            1  2018-10-10  10:15:00  ADANIENT18OCTFUT  137.55       300   \n",
       "1           -1  2018-10-11  10:00:00  ADANIENT18OCTFUT   138.3       300   \n",
       "2            1  2018-10-11  11:45:00  ADANIENT18OCTFUT  142.75       300   \n",
       "3           -1  2018-10-11  14:00:00  ADANIENT18OCTFUT   140.6       300   \n",
       "4            1  2018-10-12  09:30:00  ADANIENT18OCTFUT  143.15       300   \n",
       "...        ...         ...       ...               ...     ...       ...   \n",
       "1824        -1  2024-02-23  10:30:00  ADANIENT24MARFUT  3264.1       300   \n",
       "1825         1  2024-02-23  12:30:00  ADANIENT24MARFUT  3312.8       300   \n",
       "1826        -1  2024-02-27  11:00:00  ADANIENT24MARFUT  3330.6       300   \n",
       "1827         1  2024-02-29  10:00:00  ADANIENT24MARFUT  3269.0       300   \n",
       "1828        -1  2024-02-29  10:15:00  ADANIENT24MARFUT  3250.0       300   \n",
       "\n",
       "     entry_price exit_price      pnl  \n",
       "0         137.55      138.3    225.0  \n",
       "1          138.3     142.75  -1335.0  \n",
       "2         142.75      140.6   -645.0  \n",
       "3          140.6     143.15   -765.0  \n",
       "4         143.15      173.0   8955.0  \n",
       "...          ...        ...      ...  \n",
       "1824      3264.1     3312.8 -14610.0  \n",
       "1825      3312.8     3330.6   5340.0  \n",
       "1826      3330.6     3269.0  18480.0  \n",
       "1827      3269.0     3250.0  -5700.0  \n",
       "1828      3250.0     3278.2  -8460.0  \n",
       "\n",
       "[1829 rows x 9 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered_df.to_csv('filtered_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date and time to strings and combine into a single datetime column\n",
    "filtered_df['date'] = filtered_df['date'].astype(str)\n",
    "filtered_df['time'] = filtered_df['time'].astype(str)\n",
    "filtered_df['datetime'] = pd.to_datetime(filtered_df['date'] + ' ' + filtered_df['time'])\n",
    "\n",
    "# Calculate the final capital\n",
    "initial_capital = 800000\n",
    "filtered_df['final_capital'] = initial_capital + filtered_df['pnl'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate overall profit \n",
    "def calculate_overall_profit(data, initial_capital):\n",
    "    final_capital = data['final_capital'].iloc[-1]\n",
    "    return final_capital - initial_capital\n",
    "\n",
    "# Function to calculate overall profit percentage\n",
    "def calculate_overall_profit_percentage(data, initial_capital):\n",
    "    final_capital = data['final_capital'].iloc[-1]\n",
    "    return ((final_capital - initial_capital) / initial_capital) * 100\n",
    "\n",
    "# Function to calculate maximum drawdown\n",
    "def calculate_maximum_drawdown(data):\n",
    "    max_data = data['final_capital'].expanding(min_periods=1).max()\n",
    "    drawdown = (data['final_capital'] - max_data) / max_data\n",
    "    return drawdown.min()\n",
    "\n",
    "# Function to calculate maximum drawdown percentage\n",
    "def calculate_maximum_drawdown_percentage(data):\n",
    "    max_data = data['final_capital'].expanding(min_periods=1).max()\n",
    "    drawdown = (data['final_capital'] - max_data) / max_data\n",
    "    return drawdown.min() * 100\n",
    "\n",
    "# Function to calculate yearly profit\n",
    "def calculate_yearly_profit(data):\n",
    "    data['year'] = data['datetime'].dt.year\n",
    "    yearly_capital = data.groupby('year')['final_capital'].agg(['first', 'last'])\n",
    "    yearly_profit = yearly_capital['last'] - yearly_capital['first']\n",
    "    return yearly_profit\n",
    "\n",
    "# Function to calculate yearly profit percentage\n",
    "def calculate_yearly_profit_percentage(data):\n",
    "    yearly_profit = calculate_yearly_profit(data)\n",
    "    data['year'] = data['datetime'].dt.year\n",
    "    yearly_capital = data.groupby('year')['final_capital'].agg(['first', 'last'])\n",
    "    yearly_profit_percentage = (yearly_profit / yearly_capital['first']) * 100\n",
    "    return yearly_profit_percentage\n",
    "\n",
    "# Function to calculate yearly drawdown\n",
    "def calculate_yearly_drawdown(data):\n",
    "    yearly_drawdown = {}\n",
    "    for year, group in data.groupby('year'):\n",
    "        max_data = group['final_capital'].expanding().max()\n",
    "        drawdown = (group['final_capital'] - max_data) / max_data\n",
    "        yearly_drawdown[year] = drawdown.min()\n",
    "    return pd.Series(yearly_drawdown)\n",
    "\n",
    "# Function to calculate yearly drawdown percentage\n",
    "def calculate_yearly_drawdown_percentage(data):\n",
    "    yearly_drawdown_percentage = {}\n",
    "    for year, group in data.groupby('year'):\n",
    "        max_data = group['final_capital'].expanding().max()\n",
    "        drawdown = (group['final_capital'] - max_data) / max_data\n",
    "        yearly_drawdown_percentage[year] = drawdown.min() * 100\n",
    "    return pd.Series(yearly_drawdown_percentage)\n",
    "\n",
    "# Function to calculate CAGR\n",
    "def calculate_cagr(data, initial_capital):\n",
    "    start_value = initial_capital\n",
    "    end_value = data['final_capital'].iloc[-1]\n",
    "    n_years = (data['datetime'].iloc[-1] - data['datetime'].iloc[0]).days / 365.25\n",
    "    cagr = (end_value / start_value) ** (1 / n_years) - 1\n",
    "    return cagr * 100\n",
    "\n",
    "data = filtered_df\n",
    "overall_profit = calculate_overall_profit(data, initial_capital)\n",
    "overall_percentage = calculate_overall_profit_percentage(data, initial_capital)\n",
    "mdd = calculate_maximum_drawdown(data)\n",
    "mdd_percentage = calculate_maximum_drawdown_percentage(data)\n",
    "yearly_profit = calculate_yearly_profit(data)\n",
    "yearly_profit_percentage = calculate_yearly_profit_percentage(data)\n",
    "yearly_drawdown = calculate_yearly_drawdown(data)\n",
    "yearly_drawdown_percentage = calculate_yearly_drawdown_percentage(data)\n",
    "cagr = calculate_cagr(data, initial_capital)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Profit: 1450455.0000000014\n",
      "Overall Profit Percentage: 181.3068750000002\n",
      "Maximum Drawdown: -0.17985963113112283\n",
      "Maximum Drawdown Percentage: -17.985963113112284\n",
      "Yearly Profit: year\n",
      "2018       9825.0\n",
      "2019      12945.0\n",
      "2020      16935.0\n",
      "2021     164460.0\n",
      "2022     181335.0\n",
      "2023    1243605.0\n",
      "2024    -173670.0\n",
      "dtype: object\n",
      "Yearly Profit Percentage: year\n",
      "2018       1.22778\n",
      "2019      1.599857\n",
      "2020       2.06126\n",
      "2021     19.597352\n",
      "2022     18.064224\n",
      "2023    105.098117\n",
      "2024     -7.164235\n",
      "dtype: object\n",
      "Yearly Drawdown: 2018   -0.005299\n",
      "2019   -0.017013\n",
      "2020   -0.025262\n",
      "2021   -0.108613\n",
      "2022   -0.179860\n",
      "2023   -0.072903\n",
      "2024   -0.081075\n",
      "dtype: float64\n",
      "Yearly Drawdown Percentage: 2018    -0.529931\n",
      "2019    -1.701299\n",
      "2020    -2.526172\n",
      "2021   -10.861334\n",
      "2022   -17.985963\n",
      "2023    -7.290329\n",
      "2024    -8.107460\n",
      "dtype: float64\n",
      "CAGR: 21.161713678322116\n"
     ]
    }
   ],
   "source": [
    "# Display the results\n",
    "print(\"Overall Profit:\", overall_profit)\n",
    "print(\"Overall Profit Percentage:\", overall_percentage)\n",
    "print(\"Maximum Drawdown:\", mdd)\n",
    "print(\"Maximum Drawdown Percentage:\", mdd_percentage)\n",
    "print(\"Yearly Profit:\", yearly_profit)\n",
    "print(\"Yearly Profit Percentage:\", yearly_profit_percentage)\n",
    "print(\"Yearly Drawdown:\", yearly_drawdown)\n",
    "print(\"Yearly Drawdown Percentage:\", yearly_drawdown_percentage)\n",
    "print(\"CAGR:\", cagr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
